{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-03T05:29:51.297576Z",
     "start_time": "2025-09-03T05:29:42.067599Z"
    }
   },
   "source": [
    "# %% [markdown]\n",
    "# # Sprint Video Pose (YOLOv8) — Single \"Most Moving\" Subject\n",
    "# - Reports FPS & frame count\n",
    "# - Real-time playback with ONE selected runner (most moving / highest conf)\n",
    "# - Exports a chosen frame range as stamped images (frame#, timestamp)\n",
    "# - Writes a CSV manifest\n",
    "\n",
    "# If needed, uncomment:\n",
    "# !pip -q install ultralytics opencv-python tqdm pillow\n",
    "\n",
    "import os, csv, math\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ---------- USER SETTINGS ----------\n",
    "VIDEO_PATH   = r\"output_masked.mp4\"   # ← change this\n",
    "OUTPUT_DIR   = Path(\"./exported_frames_yolo_single\")\n",
    "MODEL_WEIGHTS = \"yolov8x-pose.pt\"\n",
    "CONF_THR      = 0.25      # detection confidence threshold\n",
    "IMGSZ         = 960       # inference size (reduce if CPU is slow)\n",
    "CONF_GAMMA    = 0.5       # how much to weight detection conf in score (0=ignore conf)\n",
    "HYSTERESIS    = 0.2       # keep previous subject if its score >= (1 - HYSTERESIS)*top_score\n",
    "MIN_BBOX_AREA = 900       # skip tiny people (in pixels^2)\n",
    "DO_ANNOTATE   = True      # draw skeleton on exported frames\n",
    "# -----------------------------------\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Open video & report stats\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(f\"Could not open video: {VIDEO_PATH}\")\n",
    "\n",
    "FPS = cap.get(cv2.CAP_PROP_FPS) or 0.0\n",
    "FRAME_COUNT = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)\n",
    "WIDTH  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) or 0)\n",
    "HEIGHT = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) or 0)\n",
    "DURATION_SEC = (FRAME_COUNT / FPS) if FPS > 0 else 0.0\n",
    "\n",
    "print(f\"Video: {VIDEO_PATH}\")\n",
    "print(f\"Resolution: {WIDTH} x {HEIGHT}\")\n",
    "print(f\"FPS: {FPS:.3f}\")\n",
    "print(f\"Total frames: {FRAME_COUNT}\")\n",
    "print(f\"Duration: {DURATION_SEC:.2f} s\")\n",
    "\n",
    "# --- Utilities ---\n",
    "def fmt_timecode(frame_idx: int, fps: float) -> str:\n",
    "    \"\"\"hh:mm:ss.mmm for a frame index at given fps.\"\"\"\n",
    "    if fps <= 0:\n",
    "        return \"00:00:00.000\"\n",
    "    total_ms = int(round((frame_idx / fps) * 1000))\n",
    "    h = total_ms // (3600 * 1000)\n",
    "    rem = total_ms % (3600 * 1000)\n",
    "    m = rem // (60 * 1000)\n",
    "    rem %= (60 * 1000)\n",
    "    s = rem // 1000\n",
    "    ms = rem % 1000\n",
    "    return f\"{h:02d}:{m:02d}:{s:02d}.{ms:03d}\"\n",
    "\n",
    "def iou_xyxy(a, b):\n",
    "    \"\"\"IoU for boxes in [x1,y1,x2,y2]. Returns 0..1.\"\"\"\n",
    "    ax1, ay1, ax2, ay2 = a\n",
    "    bx1, by1, bx2, by2 = b\n",
    "    inter_x1, inter_y1 = max(ax1, bx1), max(ay1, by1)\n",
    "    inter_x2, inter_y2 = min(ax2, bx2), min(ay2, by2)\n",
    "    iw, ih = max(0, inter_x2 - inter_x1), max(0, inter_y2 - inter_y1)\n",
    "    inter = iw * ih\n",
    "    area_a = max(0, ax2 - ax1) * max(0, ay2 - ay1)\n",
    "    area_b = max(0, bx2 - bx1) * max(0, by2 - by1)\n",
    "    denom = area_a + area_b - inter + 1e-9\n",
    "    return inter / denom\n",
    "\n",
    "# COCO keypoint edges for drawing a simple skeleton\n",
    "COCO_EDGES = [\n",
    "    (5,7), (7,9),      # left shoulder->elbow->wrist\n",
    "    (6,8), (8,10),     # right shoulder->elbow->wrist\n",
    "    (5,6),             # shoulders\n",
    "    (5,11), (6,12),    # shoulders->hips\n",
    "    (11,12),           # hips\n",
    "    (11,13), (13,15),  # left hip->knee->ankle\n",
    "    (12,14), (14,16),  # right hip->knee->ankle\n",
    "    (0,5), (0,6),      # nose->shoulders\n",
    "    (0,1), (0,2), (1,3), (2,4)  # head\n",
    "]\n",
    "\n",
    "def draw_skeleton(image, kps_xy, kps_conf=None, kp_thr=0.2, color=(0,255,0)):\n",
    "    \"\"\"Draws a COCO-17 skeleton for one person.\"\"\"\n",
    "    # Points\n",
    "    for i, (x, y) in enumerate(kps_xy):\n",
    "        if kps_conf is not None and kps_conf[i] < kp_thr: \n",
    "            continue\n",
    "        cv2.circle(image, (int(x), int(y)), 3, color, -1, cv2.LINE_AA)\n",
    "    # Lines\n",
    "    for i, j in COCO_EDGES:\n",
    "        if i >= len(kps_xy) or j >= len(kps_xy):\n",
    "            continue\n",
    "        if kps_conf is not None and (kps_conf[i] < kp_thr or kps_conf[j] < kp_thr):\n",
    "            continue\n",
    "        xi, yi = kps_xy[i]\n",
    "        xj, yj = kps_xy[j]\n",
    "        cv2.line(image, (int(xi), int(yi)), (int(xj), int(yj)), color, 2, cv2.LINE_AA)\n",
    "\n",
    "# Load model\n",
    "pose_model = YOLO(MODEL_WEIGHTS)\n",
    "print(\"YOLOv8-Pose model loaded.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video: output_masked.mp4\n",
      "Resolution: 1920 x 1080\n",
      "FPS: 30.000\n",
      "Total frames: 371\n",
      "Duration: 12.37 s\n",
      "YOLOv8-Pose model loaded.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T05:31:49.340526Z",
     "start_time": "2025-09-03T05:29:51.304577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %% [markdown]\n",
    "# ## Real-time playback (ONE subject: \"most moving\" / weighted by confidence)\n",
    "# Keys: 'q' quit, 'p' pause/resume\n",
    "\n",
    "win_name = \"YOLOv8 Pose — Single Subject\"\n",
    "cv2.namedWindow(win_name, cv2.WINDOW_NORMAL)\n",
    "\n",
    "delay_ms = int(1000 / FPS) if FPS > 0 else 1\n",
    "delay_ms = max(1, delay_ms)\n",
    "\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(f\"Could not open video: {VIDEO_PATH}\")\n",
    "\n",
    "prev_gray = None\n",
    "prev_subject_box = None  # [x1,y1,x2,y2]\n",
    "\n",
    "while True:\n",
    "    ok, frame = cap.read()\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    # Optical flow\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    flow_mag = None\n",
    "    if prev_gray is not None:\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, gray,\n",
    "                                            None, 0.5, 3, 15, 3, 5, 1.1, 0)\n",
    "        mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "        flow_mag = mag\n",
    "\n",
    "    # Pose inference\n",
    "    results = pose_model.predict(frame, conf=CONF_THR, imgsz=IMGSZ, verbose=False)\n",
    "    r = results[0]\n",
    "\n",
    "    best_idx = None\n",
    "    best_score = -1.0\n",
    "    best_box  = None\n",
    "\n",
    "    if len(r.boxes) > 0 and r.keypoints is not None:\n",
    "        boxes_xyxy = r.boxes.xyxy.cpu().numpy()\n",
    "        confs      = r.boxes.conf.cpu().numpy().reshape(-1)\n",
    "        kps_xy     = r.keypoints.xy.cpu().numpy()      # [N, 17, 2]\n",
    "        kps_conf   = getattr(r.keypoints, \"conf\", None)\n",
    "        kps_conf   = kps_conf.cpu().numpy() if kps_conf is not None else None\n",
    "\n",
    "        # Find candidate matching previous subject (for hysteresis)\n",
    "        prev_match_idx = None\n",
    "        if prev_subject_box is not None:\n",
    "            ious = [iou_xyxy(prev_subject_box, b) for b in boxes_xyxy]\n",
    "            if len(ious) > 0 and max(ious) > 0.25:\n",
    "                prev_match_idx = int(np.argmax(ious))\n",
    "\n",
    "        # Score each person\n",
    "        scores = []\n",
    "        for i, (box, conf) in enumerate(zip(boxes_xyxy, confs)):\n",
    "            x1, y1, x2, y2 = [int(v) for v in box]\n",
    "            w, h = max(0, x2 - x1), max(0, y2 - y1)\n",
    "            if w * h < MIN_BBOX_AREA:\n",
    "                scores.append(-1.0)\n",
    "                continue\n",
    "\n",
    "            motion = 0.0\n",
    "            if flow_mag is not None:\n",
    "                x1c, y1c = max(0, x1), max(0, y1)\n",
    "                x2c, y2c = min(WIDTH-1, x2), min(HEIGHT-1, y2)\n",
    "                roi = flow_mag[y1c:y2c, x1c:x2c]\n",
    "                if roi.size > 0:\n",
    "                    motion = float(np.median(roi))\n",
    "\n",
    "            score = motion * (conf ** CONF_GAMMA)\n",
    "            scores.append(score)\n",
    "\n",
    "        if len(scores) > 0:\n",
    "            top_idx = int(np.argmax(scores))\n",
    "            top_score = float(scores[top_idx])\n",
    "\n",
    "            # Hysteresis: keep previous subject if close enough to the top\n",
    "            if prev_match_idx is not None:\n",
    "                prev_score = float(scores[prev_match_idx])\n",
    "                if prev_score >= (1.0 - HYSTERESIS) * top_score:\n",
    "                    best_idx = prev_match_idx\n",
    "                    best_score = prev_score\n",
    "                else:\n",
    "                    best_idx = top_idx\n",
    "                    best_score = top_score\n",
    "            else:\n",
    "                best_idx = top_idx\n",
    "                best_score = top_score\n",
    "\n",
    "            best_box = [int(v) for v in boxes_xyxy[best_idx]]\n",
    "\n",
    "            # Draw ONLY the best subject\n",
    "            disp = frame.copy()\n",
    "            x1, y1, x2, y2 = best_box\n",
    "            cv2.rectangle(disp, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "\n",
    "            # skeleton\n",
    "            kxy = kps_xy[best_idx]\n",
    "            kc  = kps_conf[best_idx] if kps_conf is not None else None\n",
    "            draw_skeleton(disp, kxy, kc, kp_thr=0.2, color=(0, 255, 0))\n",
    "\n",
    "            # label\n",
    "            label = f\"Score: {best_score:.3f}\"\n",
    "            cv2.putText(disp, label, (x1, max(0, y1 - 10)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        else:\n",
    "            disp = frame\n",
    "    else:\n",
    "        disp = frame\n",
    "\n",
    "    # Timestamp overlay\n",
    "    curr_frame_idx = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1\n",
    "    timecode = fmt_timecode(curr_frame_idx, FPS)\n",
    "    info = f\"Frame: {curr_frame_idx}   Time: {timecode}\"\n",
    "    (tw, th), base = cv2.getTextSize(info, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)\n",
    "    cv2.rectangle(disp, (10, 10), (10 + tw + 20, 10 + th + 20), (0,0,0), -1)\n",
    "    cv2.putText(disp, info, (20, 10 + th + 5),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(win_name, disp)\n",
    "\n",
    "    # Update for next iter\n",
    "    prev_gray = gray.copy()\n",
    "    prev_subject_box = best_box\n",
    "\n",
    "    key = cv2.waitKey(delay_ms) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    if key == ord('p'):\n",
    "        while True:\n",
    "            k2 = cv2.waitKey(30) & 0xFF\n",
    "            if k2 in (ord('p'), ord('q')):\n",
    "                if k2 == ord('q'):\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    raise SystemExit\n",
    "                break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "id": "569b9a329099cb30",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T05:31:55.909711Z",
     "start_time": "2025-09-03T05:31:50.177651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %% [markdown]\n",
    "# ## Export chosen frame range (only the selected subject is drawn)\n",
    "# Set START_FRAME and END_FRAME (inclusive).\n",
    "\n",
    "START_FRAME = 150\n",
    "END_FRAME   = 160   # inclusive\n",
    "\n",
    "START_FRAME = max(0, START_FRAME)\n",
    "END_FRAME = min(FRAME_COUNT - 1, END_FRAME)\n",
    "if END_FRAME < START_FRAME:\n",
    "    raise ValueError(\"END_FRAME must be >= START_FRAME\")\n",
    "\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(f\"Could not open video: {VIDEO_PATH}\")\n",
    "\n",
    "saved_records = []\n",
    "prev_gray = None\n",
    "prev_subject_box = None\n",
    "\n",
    "for fidx in tqdm(range(START_FRAME, END_FRAME + 1), desc=\"Exporting frames\"):\n",
    "    # random seek (codec dependent); fallback: sequential read if needed\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, fidx)\n",
    "    ok, frame = cap.read()\n",
    "    if not ok:\n",
    "        ok2, frame2 = cap.read()\n",
    "        if not ok2:\n",
    "            print(f\"[WARN] Could not read frame {fidx}, skipping.\")\n",
    "            continue\n",
    "        frame = frame2\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    flow_mag = None\n",
    "    if prev_gray is not None:\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, gray,\n",
    "                                            None, 0.5, 3, 15, 3, 5, 1.1, 0)\n",
    "        mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "        flow_mag = mag\n",
    "\n",
    "    results = pose_model.predict(frame, conf=CONF_THR, imgsz=IMGSZ, verbose=False)\n",
    "    r = results[0]\n",
    "\n",
    "    out_img = frame.copy()\n",
    "    best_box = None\n",
    "\n",
    "    if len(r.boxes) > 0 and r.keypoints is not None and DO_ANNOTATE:\n",
    "        boxes_xyxy = r.boxes.xyxy.cpu().numpy()\n",
    "        confs      = r.boxes.conf.cpu().numpy().reshape(-1)\n",
    "        kps_xy     = r.keypoints.xy.cpu().numpy()\n",
    "        kps_conf   = getattr(r.keypoints, \"conf\", None)\n",
    "        kps_conf   = kps_conf.cpu().numpy() if kps_conf is not None else None\n",
    "\n",
    "        prev_match_idx = None\n",
    "        if prev_subject_box is not None:\n",
    "            ious = [iou_xyxy(prev_subject_box, b) for b in boxes_xyxy]\n",
    "            if len(ious) > 0 and max(ious) > 0.25:\n",
    "                prev_match_idx = int(np.argmax(ious))\n",
    "\n",
    "        scores = []\n",
    "        for i, (box, conf) in enumerate(zip(boxes_xyxy, confs)):\n",
    "            x1, y1, x2, y2 = [int(v) for v in box]\n",
    "            w, h = max(0, x2 - x1), max(0, y2 - y1)\n",
    "            if w * h < MIN_BBOX_AREA:\n",
    "                scores.append(-1.0)\n",
    "                continue\n",
    "\n",
    "            motion = 0.0\n",
    "            if flow_mag is not None:\n",
    "                x1c, y1c = max(0, x1), max(0, y1)\n",
    "                x2c, y2c = min(WIDTH-1, x2), min(HEIGHT-1, y2)\n",
    "                roi = flow_mag[y1c:y2c, x1c:x2c]\n",
    "                if roi.size > 0:\n",
    "                    motion = float(np.median(roi))\n",
    "\n",
    "            score = motion * (conf ** CONF_GAMMA)\n",
    "            scores.append(score)\n",
    "\n",
    "        if len(scores) > 0:\n",
    "            top_idx = int(np.argmax(scores))\n",
    "            top_score = float(scores[top_idx])\n",
    "\n",
    "            if prev_match_idx is not None and float(scores[prev_match_idx]) >= (1.0 - HYSTERESIS) * top_score:\n",
    "                best_idx = prev_match_idx\n",
    "            else:\n",
    "                best_idx = top_idx\n",
    "\n",
    "            best_box = [int(v) for v in boxes_xyxy[best_idx]]\n",
    "\n",
    "            # Draw only the best subject\n",
    "            x1, y1, x2, y2 = best_box\n",
    "            cv2.rectangle(out_img, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "            kxy = kps_xy[best_idx]\n",
    "            kc  = kps_conf[best_idx] if kps_conf is not None else None\n",
    "            draw_skeleton(out_img, kxy, kc, kp_thr=0.2, color=(0, 255, 0))\n",
    "\n",
    "    # Stamp frame number + timestamp\n",
    "    timecode = fmt_timecode(fidx, FPS)\n",
    "    label = f\"Frame: {fidx}   Time: {timecode}\"\n",
    "    (tw, th), base = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)\n",
    "    cv2.rectangle(out_img, (10, 10), (10 + tw + 20, 10 + th + 20), (0,0,0), -1)\n",
    "    cv2.putText(out_img, label, (20, 10 + th + 5),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "    out_path = OUTPUT_DIR / f\"frame_{fidx:06d}.jpg\"\n",
    "    cv2.imwrite(str(out_path), out_img)\n",
    "\n",
    "    saved_records.append({\n",
    "        \"frame\": fidx,\n",
    "        \"time_seconds\": (fidx / FPS) if FPS > 0 else 0.0,\n",
    "        \"timecode\": timecode,\n",
    "        \"image_path\": str(out_path.resolve())\n",
    "    })\n",
    "\n",
    "    prev_gray = gray.copy()\n",
    "    prev_subject_box = best_box\n",
    "\n",
    "cap.release()\n",
    "print(f\"Saved {len(saved_records)} frames to: {OUTPUT_DIR.resolve()}\")\n"
   ],
   "id": "bbcaacffe4c4c07b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exporting frames: 100%|██████████| 11/11 [00:05<00:00,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 11 frames to: C:\\Users\\yenul\\PycharmProjects\\YOLO_speed_tracker\\exported_frames_yolo_single\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T05:31:55.957897Z",
     "start_time": "2025-09-03T05:31:55.943717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %% [markdown]\n",
    "# ## Write CSV\n",
    "\n",
    "CSV_PATH = OUTPUT_DIR / \"exported_frames_manifest.csv\"\n",
    "with open(CSV_PATH, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"frame\",\"time_seconds\",\"timecode\",\"image_path\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(saved_records)\n",
    "\n",
    "print(f\"CSV written to: {CSV_PATH.resolve()}\")\n"
   ],
   "id": "8448b38438cacb45",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV written to: C:\\Users\\yenul\\PycharmProjects\\YOLO_speed_tracker\\exported_frames_yolo_single\\exported_frames_manifest.csv\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
